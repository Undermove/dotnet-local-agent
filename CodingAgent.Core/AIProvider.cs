using System.Text.Json;
using Anthropic.SDK;
using Anthropic.SDK.Messaging;
using OpenAI;
using OpenAI.Chat;
using System.ClientModel;

namespace CodingAgent.Core;

public enum AIProviderType
{
    Anthropic,
    LMStudio
}

public interface IAIProvider
{
    Task<string> SendMessageAsync(string message, List<object>? tools = null, bool verbose = false);
}

public class AnthropicProvider : IAIProvider
{
    private readonly AnthropicClient _client;
    private readonly string _model;

    public AnthropicProvider(string apiKey, string model = "claude-3-5-sonnet-20241022")
    {
        _client = new AnthropicClient(apiKey);
        _model = model;
    }

    public async Task<string> SendMessageAsync(string message, List<object>? tools = null, bool verbose = false)
    {
        var messageParams = new MessageParameters
        {
            Messages = [new Message(RoleType.User, message)],
            Model = _model,
            MaxTokens = 4096,
            Stream = false
        };

        if (tools != null && tools.Count > 0)
        {
            messageParams.Tools = tools.Cast<Anthropic.SDK.Common.Tool>().ToList();
        }

        if (verbose)
        {
            Console.WriteLine($"ü§ñ Sending message to Claude ({_model})...");
        }

        var response = await _client.Messages.GetClaudeMessageAsync(messageParams);
        
        if (response.Content.FirstOrDefault() is TextContent textContent)
        {
            return textContent.Text;
        }

        return "No response received.";
    }
}

public class LMStudioProvider : IAIProvider
{
    private readonly OpenAIClient _client;
    private readonly string _model;

    public LMStudioProvider(string baseUrl = "http://localhost:1234", string model = "local-model")
    {
        var options = new OpenAIClientOptions
        {
            Endpoint = new Uri($"{baseUrl}/v1")
        };
        
        // LM Studio –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–∞–ª—å–Ω–æ–≥–æ API –∫–ª—é—á–∞, –Ω–æ SDK —Ç—Ä–µ–±—É–µ—Ç –Ω–µ–ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        _client = new OpenAIClient(new ApiKeyCredential("lm-studio"), options);
        _model = model;
    }

    public async Task<string> SendMessageAsync(string message, List<object>? tools = null, bool verbose = false)
    {
        var messages = new List<ChatMessage>
        {
            new UserChatMessage(message)
        };

        // –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: LM Studio –º–æ–∂–µ—Ç –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å tools –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–æ–¥–µ–ª–∏
        // –ü–æ—ç—Ç–æ–º—É –ø–æ–∫–∞ –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º tools –¥–ª—è LM Studio

        if (verbose)
        {
            Console.WriteLine($"ü§ñ Sending message to LM Studio ({_model})...");
        }

        try
        {
            var chatClient = _client.GetChatClient(_model);
            var response = await chatClient.CompleteChatAsync(messages, new ChatCompletionOptions
            {
                Temperature = 0.7f
            });
            
            return response.Value.Content[0].Text;
        }
        catch (Exception ex)
        {
            return $"Error connecting to LM Studio: {ex.Message}. Make sure LM Studio is running on the configured endpoint";
        }
    }
}

public static class AIProviderFactory
{
    public static IAIProvider CreateProvider(AIProviderType providerType, string? apiKey = null, string? baseUrl = null, string? model = null)
    {
        return providerType switch
        {
            AIProviderType.Anthropic => new AnthropicProvider(
                apiKey ?? Environment.GetEnvironmentVariable("ANTHROPIC_API_KEY") ?? throw new InvalidOperationException("ANTHROPIC_API_KEY environment variable is not set"),
                model ?? "claude-3-5-sonnet-20241022"
            ),
            AIProviderType.LMStudio => new LMStudioProvider(
                baseUrl ?? "http://localhost:1234",
                model ?? "local-model"
            ),
            _ => throw new ArgumentException($"Unsupported provider type: {providerType}")
        };
    }
}